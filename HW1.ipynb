{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "sample = pd.read_csv(\"data/sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>Length_of_Conveyer</th>\n",
       "      <th>TypeOfSteel_A300</th>\n",
       "      <th>TypeOfSteel_A400</th>\n",
       "      <th>Steel_Plate_Thickness</th>\n",
       "      <th>Edges_Index</th>\n",
       "      <th>Empty_Index</th>\n",
       "      <th>Square_Index</th>\n",
       "      <th>Outside_X_Index</th>\n",
       "      <th>Edges_X_Index</th>\n",
       "      <th>Edges_Y_Index</th>\n",
       "      <th>Outside_Global_Index</th>\n",
       "      <th>LogOfAreas</th>\n",
       "      <th>Log_X_Index</th>\n",
       "      <th>Log_Y_Index</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "      <th>Pastry</th>\n",
       "      <th>Z_Scratch</th>\n",
       "      <th>K_Scatch</th>\n",
       "      <th>Stains</th>\n",
       "      <th>Dirtiness</th>\n",
       "      <th>Bumps</th>\n",
       "      <th>Other_Faults</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>584</td>\n",
       "      <td>590</td>\n",
       "      <td>909972</td>\n",
       "      <td>909977</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2274</td>\n",
       "      <td>113</td>\n",
       "      <td>140</td>\n",
       "      <td>1358</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7393</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2041</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>0.6990</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-0.0104</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>808</td>\n",
       "      <td>816</td>\n",
       "      <td>728350</td>\n",
       "      <td>728372</td>\n",
       "      <td>433</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>44478</td>\n",
       "      <td>70</td>\n",
       "      <td>111</td>\n",
       "      <td>1687</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0.7772</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.2581</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6365</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.7324</td>\n",
       "      <td>0.7419</td>\n",
       "      <td>-0.2997</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>192</td>\n",
       "      <td>2212076</td>\n",
       "      <td>2212144</td>\n",
       "      <td>11388</td>\n",
       "      <td>705</td>\n",
       "      <td>420</td>\n",
       "      <td>1311391</td>\n",
       "      <td>29</td>\n",
       "      <td>141</td>\n",
       "      <td>1400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.5282</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.1077</td>\n",
       "      <td>0.2363</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0564</td>\n",
       "      <td>2.1790</td>\n",
       "      <td>2.2095</td>\n",
       "      <td>-0.0105</td>\n",
       "      <td>-0.0944</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>781</td>\n",
       "      <td>789</td>\n",
       "      <td>3353146</td>\n",
       "      <td>3353173</td>\n",
       "      <td>210</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>3202</td>\n",
       "      <td>114</td>\n",
       "      <td>134</td>\n",
       "      <td>1387</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.7202</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.9310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.3222</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.4314</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.0402</td>\n",
       "      <td>0.4025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1540</td>\n",
       "      <td>1560</td>\n",
       "      <td>618457</td>\n",
       "      <td>618502</td>\n",
       "      <td>521</td>\n",
       "      <td>72</td>\n",
       "      <td>67</td>\n",
       "      <td>48231</td>\n",
       "      <td>82</td>\n",
       "      <td>111</td>\n",
       "      <td>1692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7694</td>\n",
       "      <td>1.4150</td>\n",
       "      <td>1.8808</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>-0.2455</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  X_Minimum  X_Maximum  Y_Minimum  ...  Stains  Dirtiness  Bumps  Other_Faults\n",
       "0   0        584        590     909972  ...       1          0      0             0\n",
       "1   1        808        816     728350  ...       0          0      0             1\n",
       "2   2         39        192    2212076  ...       0          0      0             0\n",
       "3   3        781        789    3353146  ...       0          0      0             0\n",
       "4   4       1540       1560     618457  ...       0          0      0             1\n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(\"id\",inplace=True,axis=1)\n",
    "test.drop(\"id\",inplace=True,axis=1)\n",
    "id = sample[\"id\"]\n",
    "names = sample.columns.tolist()\n",
    "sample.drop(\"id\",inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19219, 27)\n",
      "(19219, 7)\n"
     ]
    }
   ],
   "source": [
    "y_col = sample.columns.tolist()\n",
    "\n",
    "y_train = train[y_col]\n",
    "X_train = train.drop(y_col,axis=1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X_Minimum</th>\n",
       "      <th>X_Maximum</th>\n",
       "      <th>Y_Minimum</th>\n",
       "      <th>Y_Maximum</th>\n",
       "      <th>Pixels_Areas</th>\n",
       "      <th>X_Perimeter</th>\n",
       "      <th>Y_Perimeter</th>\n",
       "      <th>Sum_of_Luminosity</th>\n",
       "      <th>Minimum_of_Luminosity</th>\n",
       "      <th>Maximum_of_Luminosity</th>\n",
       "      <th>Length_of_Conveyer</th>\n",
       "      <th>TypeOfSteel_A300</th>\n",
       "      <th>TypeOfSteel_A400</th>\n",
       "      <th>Steel_Plate_Thickness</th>\n",
       "      <th>Edges_Index</th>\n",
       "      <th>Empty_Index</th>\n",
       "      <th>Square_Index</th>\n",
       "      <th>Outside_X_Index</th>\n",
       "      <th>Edges_X_Index</th>\n",
       "      <th>Edges_Y_Index</th>\n",
       "      <th>Outside_Global_Index</th>\n",
       "      <th>LogOfAreas</th>\n",
       "      <th>Log_X_Index</th>\n",
       "      <th>Log_Y_Index</th>\n",
       "      <th>Orientation_Index</th>\n",
       "      <th>Luminosity_Index</th>\n",
       "      <th>SigmoidOfAreas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>584</td>\n",
       "      <td>590</td>\n",
       "      <td>909972</td>\n",
       "      <td>909977</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2274</td>\n",
       "      <td>113</td>\n",
       "      <td>140</td>\n",
       "      <td>1358</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7393</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2041</td>\n",
       "      <td>0.9031</td>\n",
       "      <td>0.6990</td>\n",
       "      <td>-0.5000</td>\n",
       "      <td>-0.0104</td>\n",
       "      <td>0.1417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>808</td>\n",
       "      <td>816</td>\n",
       "      <td>728350</td>\n",
       "      <td>728372</td>\n",
       "      <td>433</td>\n",
       "      <td>20</td>\n",
       "      <td>54</td>\n",
       "      <td>44478</td>\n",
       "      <td>70</td>\n",
       "      <td>111</td>\n",
       "      <td>1687</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0.7772</td>\n",
       "      <td>0.2878</td>\n",
       "      <td>0.2581</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6365</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.7324</td>\n",
       "      <td>0.7419</td>\n",
       "      <td>-0.2997</td>\n",
       "      <td>0.9491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>192</td>\n",
       "      <td>2212076</td>\n",
       "      <td>2212144</td>\n",
       "      <td>11388</td>\n",
       "      <td>705</td>\n",
       "      <td>420</td>\n",
       "      <td>1311391</td>\n",
       "      <td>29</td>\n",
       "      <td>141</td>\n",
       "      <td>1400</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.5282</td>\n",
       "      <td>0.9895</td>\n",
       "      <td>0.1077</td>\n",
       "      <td>0.2363</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0564</td>\n",
       "      <td>2.1790</td>\n",
       "      <td>2.2095</td>\n",
       "      <td>-0.0105</td>\n",
       "      <td>-0.0944</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>781</td>\n",
       "      <td>789</td>\n",
       "      <td>3353146</td>\n",
       "      <td>3353173</td>\n",
       "      <td>210</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>3202</td>\n",
       "      <td>114</td>\n",
       "      <td>134</td>\n",
       "      <td>1387</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.7202</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.9310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.3222</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>1.4314</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>-0.0402</td>\n",
       "      <td>0.4025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1540</td>\n",
       "      <td>1560</td>\n",
       "      <td>618457</td>\n",
       "      <td>618502</td>\n",
       "      <td>521</td>\n",
       "      <td>72</td>\n",
       "      <td>67</td>\n",
       "      <td>48231</td>\n",
       "      <td>82</td>\n",
       "      <td>111</td>\n",
       "      <td>1692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1211</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7694</td>\n",
       "      <td>1.4150</td>\n",
       "      <td>1.8808</td>\n",
       "      <td>0.9158</td>\n",
       "      <td>-0.2455</td>\n",
       "      <td>0.9998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1009</td>\n",
       "      <td>1033</td>\n",
       "      <td>899231</td>\n",
       "      <td>899307</td>\n",
       "      <td>409</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>47513</td>\n",
       "      <td>86</td>\n",
       "      <td>118</td>\n",
       "      <td>1650</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0.2761</td>\n",
       "      <td>0.4136</td>\n",
       "      <td>0.4091</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.5454</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6117</td>\n",
       "      <td>0.9542</td>\n",
       "      <td>1.4150</td>\n",
       "      <td>0.5909</td>\n",
       "      <td>-0.1890</td>\n",
       "      <td>0.8749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>596</td>\n",
       "      <td>607</td>\n",
       "      <td>739072</td>\n",
       "      <td>7390760</td>\n",
       "      <td>204</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>22478</td>\n",
       "      <td>89</td>\n",
       "      <td>127</td>\n",
       "      <td>1373</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.8331</td>\n",
       "      <td>0.2744</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.3096</td>\n",
       "      <td>1.1761</td>\n",
       "      <td>1.3222</td>\n",
       "      <td>0.3158</td>\n",
       "      <td>-0.1497</td>\n",
       "      <td>0.5212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1673</td>\n",
       "      <td>1687</td>\n",
       "      <td>294065</td>\n",
       "      <td>294091</td>\n",
       "      <td>571</td>\n",
       "      <td>38</td>\n",
       "      <td>57</td>\n",
       "      <td>53142</td>\n",
       "      <td>77</td>\n",
       "      <td>110</td>\n",
       "      <td>1692</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.4326</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.5686</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7528</td>\n",
       "      <td>1.3802</td>\n",
       "      <td>1.7559</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>-0.2661</td>\n",
       "      <td>0.9408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>507</td>\n",
       "      <td>521</td>\n",
       "      <td>203252</td>\n",
       "      <td>203261</td>\n",
       "      <td>101</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>12530</td>\n",
       "      <td>124</td>\n",
       "      <td>140</td>\n",
       "      <td>1360</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.7210</td>\n",
       "      <td>0.4815</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0043</td>\n",
       "      <td>1.3802</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>-0.6667</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.3601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>893</td>\n",
       "      <td>907</td>\n",
       "      <td>1341292</td>\n",
       "      <td>1341296</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>7052</td>\n",
       "      <td>87</td>\n",
       "      <td>133</td>\n",
       "      <td>1687</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0.8088</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7324</td>\n",
       "      <td>0.6990</td>\n",
       "      <td>1.1761</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>-0.1228</td>\n",
       "      <td>0.1400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X_Minimum  X_Maximum  ...  Luminosity_Index  SigmoidOfAreas\n",
       "0        584        590  ...           -0.0104          0.1417\n",
       "1        808        816  ...           -0.2997          0.9491\n",
       "2         39        192  ...           -0.0944          1.0000\n",
       "3        781        789  ...           -0.0402          0.4025\n",
       "4       1540       1560  ...           -0.2455          0.9998\n",
       "5       1009       1033  ...           -0.1890          0.8749\n",
       "6        596        607  ...           -0.1497          0.5212\n",
       "7       1673       1687  ...           -0.2661          0.9408\n",
       "8        507        521  ...            0.0305          0.3601\n",
       "9        893        907  ...           -0.1228          0.1400\n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(X_train.values)\n",
    "y = torch.Tensor(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-155-7b4c2dd35e96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py\u001b[0m in \u001b[0;36mlegacy_get_string\u001b[1;34m(size_average, reduce, emit_warning)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mreduce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "N, D_in,  D_out = 19219, 27, 7\n",
    "H = [500,1000,500,100]\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H[0]),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(H[0], H[1]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H[1], H[2]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H[2], D_out)\n",
    ")\n",
    "\n",
    "l_r = 1e-10\n",
    "for i in range(10):\n",
    "    y_pred = model(x)\n",
    "    loss = torch.nn.MSELoss(y_pred,y)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= l_r*param.grad\n",
    "    model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = y[:,1].reshape(19219, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "tensor(1.2534, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "N, D_in,  D_out = 19219, 27, 1\n",
    "H = [500,1000,500,100]\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H[0]),\n",
    "    torch.nn.LeakyReLU(),\n",
    "    torch.nn.Linear(H[0], H[1]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H[1], H[2]),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H[2], D_out)#,\n",
    " #   torch.nn.Softmax()\n",
    "    \n",
    ")\n",
    "\n",
    "l_r = 1e-2\n",
    "for i in range(200):\n",
    "    l_r  = 1e-9/(i+1)\n",
    "    y_pred = model(x)\n",
    "    #loss = torch.nn.functional.binary_cross_entropy_with_logits(y_pred,y1)\n",
    "    loss = torch.nn.functional.binary_cross_entropy_with_logits(y_pred,y)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= l_r*param.grad\n",
    "    model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-212-6ed6405aa3d4>:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  torch.nn.functional.softmax(y_pred_2l)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        ...,\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_2l = torch.Tensor(test.values)\n",
    "y_pred_2l = model(X_test_2l)\n",
    "torch.nn.functional.softmax(y_pred_2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2l = pd.DataFrame(y_pred_2l).astype(\"float\")\n",
    "y_pred_2l.columns = sample.columns\n",
    "y_pred_2l[\"id\"] = id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2l = y_pred_2l[names]\n",
    "y_pred_2l.to_csv(\"output/2lnn_1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
